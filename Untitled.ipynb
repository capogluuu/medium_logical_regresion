{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*İlk başta hangi kütüphaneleri kullanacaksak ilk onları import etmekle başlıyoruz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.replace(to_replace = np.nan, value =-99999) \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Yapmamız gereken ilk şey elimizdeki datayı okuyup işlem yapmak için uygun bir hale getirmektir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>calorie</th>\n",
       "      <th>water</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>fiber</th>\n",
       "      <th>sugar</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sfat</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>...</th>\n",
       "      <th>iron</th>\n",
       "      <th>folat</th>\n",
       "      <th>pantotenik</th>\n",
       "      <th>fosfor</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>cinko</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>manganese</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>717</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>51.368</td>\n",
       "      <td>215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>0.11</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>76.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.41</td>\n",
       "      <td>3.71</td>\n",
       "      <td>94.900.000</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>174</td>\n",
       "      <td>20</td>\n",
       "      <td>02.05</td>\n",
       "      <td>66</td>\n",
       "      <td>21.8</td>\n",
       "      <td>14</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>79.53</td>\n",
       "      <td>17.99</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>67</td>\n",
       "      <td>60.000.000</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.8</td>\n",
       "      <td>56.000.000</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>132.46</td>\n",
       "      <td>73.13</td>\n",
       "      <td>12.46</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.59</td>\n",
       "      <td>6.37</td>\n",
       "      <td>6.57</td>\n",
       "      <td>2.23</td>\n",
       "      <td>22.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>15.53</td>\n",
       "      <td>0.39</td>\n",
       "      <td>79.5</td>\n",
       "      <td>21.38</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>103.29</td>\n",
       "      <td>79.04</td>\n",
       "      <td>04.01</td>\n",
       "      <td>01.07</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11.47</td>\n",
       "      <td>4.53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>28.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>78.47</td>\n",
       "      <td>16.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2495</td>\n",
       "      <td>2495</td>\n",
       "      <td>502</td>\n",
       "      <td>4.23</td>\n",
       "      <td>64.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>48.25</td>\n",
       "      <td>4.91</td>\n",
       "      <td>24.85</td>\n",
       "      <td>18.96</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>81.000.000</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>27</td>\n",
       "      <td>01.06</td>\n",
       "      <td>197</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>2496</td>\n",
       "      <td>128</td>\n",
       "      <td>73.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.75</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.28</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>2.32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.35</td>\n",
       "      <td>204</td>\n",
       "      <td>14</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.100.000</td>\n",
       "      <td>17.7</td>\n",
       "      <td>14</td>\n",
       "      <td>Hayvansal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2497</td>\n",
       "      <td>2497</td>\n",
       "      <td>129</td>\n",
       "      <td>680.100.000</td>\n",
       "      <td>27.99</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.28</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.900.000</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2498</td>\n",
       "      <td>2498</td>\n",
       "      <td>455</td>\n",
       "      <td>2.75</td>\n",
       "      <td>70.73</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.48</td>\n",
       "      <td>7.3</td>\n",
       "      <td>16.4</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.64</td>\n",
       "      <td>38</td>\n",
       "      <td>577</td>\n",
       "      <td>302</td>\n",
       "      <td>72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>274</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.549</td>\n",
       "      <td>Bitkisel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2499</td>\n",
       "      <td>2499</td>\n",
       "      <td>79.81</td>\n",
       "      <td>80.36</td>\n",
       "      <td>14.65</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.72</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.43</td>\n",
       "      <td>54.77</td>\n",
       "      <td>17.91</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Mix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID calorie        water carbohydrate  fiber  sugar protein    fat  \\\n",
       "0        0     717        17.94         0.06      0   0.06    0.85  81.11   \n",
       "1        1     116        76.78            0      0      0   19.41   3.71   \n",
       "2        2      75        79.53        17.99    4.9    4.8     1.2    0.3   \n",
       "3        3  132.46        73.13        12.46   1.59   1.59    6.37   6.57   \n",
       "4        4  103.29        79.04        04.01  01.07   2.38   11.47   4.53   \n",
       "...    ...     ...          ...          ...    ...    ...     ...    ...   \n",
       "2495  2495     502         4.23         64.8    1.1  48.25    4.91  24.85   \n",
       "2496  2496     128        73.03            0      0      0   21.75   3.85   \n",
       "2497  2497     129  680.100.000        27.99    0.4   0.05    2.67   0.28   \n",
       "2498  2498     455         2.75        70.73    6.9  15.48     7.3   16.4   \n",
       "2499  2499   79.81        80.36        14.65   1.33   0.84    2.72   1.35   \n",
       "\n",
       "            sfat cholesterol  ...        iron  folat  pantotenik  fosfor  \\\n",
       "0         51.368         215  ...        0.02      3        0.11      24   \n",
       "1     94.900.000          89  ...        0.76      4         1.1     174   \n",
       "2           0.05           0  ...        0.59     67  60.000.000      71   \n",
       "3           2.23       22.57  ...        0.98  15.53        0.39    79.5   \n",
       "4           0.77       28.62  ...        0.71   15.6         0.4   78.47   \n",
       "...          ...         ...  ...         ...    ...         ...     ...   \n",
       "2495       18.96           7  ...  81.000.000     26           0     105   \n",
       "2496        1.28          39  ...        2.32      8        0.35     204   \n",
       "2497          77           0  ...         1.2     58           0      43   \n",
       "2498        3.21           0  ...        2.64     38         577     302   \n",
       "2499        0.03        2.53  ...         0.3   8.14        0.43   54.77   \n",
       "\n",
       "     magnesium  cinko     copper selenium   manganese      Class  \n",
       "0            2   0.09         16        1           4  Hayvansal  \n",
       "1           20  02.05         66     21.8          14  Hayvansal  \n",
       "2           29   0.59       0.12      1.8  56.000.000   Bitkisel  \n",
       "3        21.38   1.36       0.15      5.2        0.24        Mix  \n",
       "4        16.49   0.46       0.05      8.5         0.1  Hayvansal  \n",
       "...        ...    ...        ...      ...         ...        ...  \n",
       "2495        27  01.06        197      4.3           0        Mix  \n",
       "2496        14   6.94  7.100.000     17.7          14  Hayvansal  \n",
       "2497        12   0.49  6.900.000      7.5           0   Bitkisel  \n",
       "2498        72   1.64        274      9.9       1.549   Bitkisel  \n",
       "2499     17.91   0.29       0.12      1.2        0.12        Mix  \n",
       "\n",
       "[2500 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train= pd.read_csv(\"train.csv\",sep = \",\")\n",
    "df= data_train.copy()\n",
    "df=df.dropna() \n",
    "data_train\n",
    " #eksik gözlemleri giderdi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Elimizdeki veride karşılaşacaımız iki tip sıkıntı var \n",
    "1. si 84.000.000 gibi girdilerin string şeklinde algılanması\n",
    "2. si \"Mikrogram\" şeklinde elimzide veriler olması\n",
    "\n",
    "Bu iki tip sıkıntıyı yerlerine o sütunun ortalama değerlerini vererek bir nevi çözününü yapmış oluyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = df.columns \n",
    "liste = liste[:-1] \n",
    "for i in liste:\n",
    "    df[i]=pd.to_numeric(df[i] ,errors='coerce')\n",
    "    df[i]=df[i].fillna(df[i].mean(), inplace= False)\n",
    "    df[i] = df[i].replace(\"Mikrogram\",df[i].mean())                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada bizim belirlemek istediğimiz kategorik değişkenlerin train datasındaki sayısını görüyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitkisel     1180\n",
      "Hayvansal     688\n",
      "Mix           632\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df[\"Class\"].value_counts())\n",
    "df[\"Class\"].value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tercihen) Bir sözlük yardımıyla tüm kategorik değişkenlerin int değerler almasını sağladık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sozluk={'Hayvansal':0,'Bitkisel':1,'Mix':2}\n",
    "df.Class = [sozluk [item] for item in df.Class] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Öncelikle LogisticRegression işlemi için hangi kütüphanelerden neyleri kullanmamız gerekiyorsa onları import ediyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu adımda ise train_test_split yapısıyla datanın 0.25 ini test diğer 0.75 ini train için ayırıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Class\n",
    "X = df.drop([\"Class\"],axis =1)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 211)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler Standardizasyon görevini yerine getirir. Genellikle bir veri kümesi, ölçek olarak farklı olan değişkenleri içerir. Makine öğrenme modeli oluştururken bu farklı ölçekli verilerin ortak bir ölçeğe sahip olmaları için StandardScaler kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu aşamada da modeli eğitip test için train_test_split da ayırdığımız X_test değişkeni üzerindeki tahminleri.predict ile\n",
    "Tahmin skoruna da accuracy_score(y_test,y_pred) ile erişebildik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584\n"
     ]
    }
   ],
   "source": [
    "classifier= LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Eğer her bir kategorik deği̇şken için her bir columns un önemlilik kat sayi değerlerini öğrenmek isterseniz\n",
    "\"coef_\" Bütün bağımsız değişkenlerin önemlilik kat sayı değerlerini verir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00780672, -0.20457237,  0.06948891, -0.19478406, -0.88067322,\n",
       "        -0.02591789,  1.13912732,  0.2859024 ,  0.09733899,  0.60126571,\n",
       "         0.01744637,  0.39190859,  0.19293479,  0.1378262 , -0.26764377,\n",
       "         0.47304344, -0.44783524,  0.09653533,  0.03496418,  1.38912385,\n",
       "        -0.06409533,  0.08973501,  0.00543118, -0.62269616, -0.00957756,\n",
       "         0.06411463, -0.15575302, -1.18716688,  0.31727694,  0.25484183,\n",
       "         0.2027899 , -0.03279492],\n",
       "       [-0.02020667, -0.08376287, -0.08099716,  0.0452878 ,  0.83821484,\n",
       "        -0.03227376, -1.13324256,  0.03158308,  0.01996386, -0.95885319,\n",
       "        -0.00211346, -0.14920309, -0.23150349, -0.11354481,  0.37000174,\n",
       "        -0.68840691,  0.23642245, -0.12594527,  0.10845388, -1.77537837,\n",
       "         0.00788511, -0.09741166,  0.10913488,  0.64206303,  0.02229547,\n",
       "         0.05731402, -0.20202734,  0.98614767, -0.11742211, -0.12746391,\n",
       "        -0.07124901,  0.15129188],\n",
       "       [ 0.01239995,  0.28833524,  0.01150825,  0.14949626,  0.04245837,\n",
       "         0.05819165, -0.00588476, -0.31748547, -0.11730285,  0.35758748,\n",
       "        -0.01533291, -0.2427055 ,  0.0385687 , -0.02428139, -0.10235797,\n",
       "         0.21536347,  0.21141279,  0.02940993, -0.14341806,  0.38625452,\n",
       "         0.05621022,  0.00767665, -0.11456607, -0.01936687, -0.0127179 ,\n",
       "        -0.12142865,  0.35778037,  0.20101922, -0.19985483, -0.12737792,\n",
       "        -0.13154089, -0.11849696]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
